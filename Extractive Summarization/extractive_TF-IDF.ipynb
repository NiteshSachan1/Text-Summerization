import nltk
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from nltk.tokenize import sent_tokenize, word_tokenize
from nltk.corpus import stopwords
import string

# Download required NLTK data files
nltk.download('punkt')
nltk.download('stopwords')

def preprocess_text(text):
    # Tokenize text into sentences
    sentences = sent_tokenize(text)
    
    # Tokenize each sentence into words
    words = [word_tokenize(sentence.lower()) for sentence in sentences]
    
    # Remove stopwords and punctuation
    stop_words = set(stopwords.words('english'))
    words_filtered = [[word for word in sentence if word not in stop_words and word not in string.punctuation] for sentence in words]
    
    # Join words back into sentences
    sentences_filtered = [' '.join(sentence) for sentence in words_filtered]
    
    return sentences_filtered

def tfidf_summarize(text, num_sentences=2):
    # Preprocess the text
    sentences = preprocess_text(text)
    
    # Create the TF-IDF vectorizer
    tfidf_vectorizer = TfidfVectorizer()
    
    # Fit and transform the data
    tfidf_matrix = tfidf_vectorizer.fit_transform(sentences)
    
    # Calculate sentence scores (sum of TF-IDF values)
    sentence_scores = np.array(tfidf_matrix.sum(axis=1)).flatten()
    
    # Sort sentences by their scores in descending order
    sorted_indices = np.argsort(-sentence_scores)
    
    # Select the top sentences
    top_sentence_indices = sorted_indices[:num_sentences]
    top_sentence_indices.sort()  # sort by their original order
    
    # Extract and return the top sentences
    summary_sentences = [sentences[i] for i in top_sentence_indices]
    summary = ' '.join(summary_sentences)
    
    return summary

# Example usage:
if __name__ == '__main__':
    # Example text
    example_text = """
    Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence 
    concerned with the interactions between computers and human language, in particular how to program computers to 
    process and analyze large amounts of natural language data. Challenges in natural language processing frequently 
    involve speech recognition, natural language understanding, and natural language generation.
    """
    
    # Summarize the text
    print("Original Text")
    print(example_text)
    summary = tfidf_summarize(example_text, num_sentences=2)
    print("Summary:")
    print(summary)
